[TOC]

# bash

#### Shell下重复多次执行命令

https://zhuanlan.zhihu.com/p/28023094

```bash
$ watch -n 1 date
```

```bash
while true; do date; sleep 1; done
```

```bash
seq 10 | xargs -i date
# 注意这里的-i的作用
```



#### ps aux输出详解

`ps aux`

| USER  | PID   | %CPU | %MEM | VSZ   | RSS  | TTY  | STAT | START | TIME | COMMAND                                                      |
| :---- | :---- | :--- | :--- | :---- | :--- | :--- | :--- | :---- | :--- | :----------------------------------------------------------- |
| ppipe | 31723 | 0.0  | 0.0  | 17960 | 1528 | ?    | S    | May20 | 0:03 | rsync -avzL 218.244.142.25::output_25 /datayes/pipeline/newsCrawler/data_25/ |
stat 中的参数意义如下：
   - D 不可中断 Uninterruptible（usually IO）
   - R 正在运行，或在队列中的进程
   - S 处于休眠状态
   - T 停止或被追踪
   - Z 僵尸进程
   - W 进入内存交换（从内核2.6开始无效）
   - X   死掉的进程

< 高优先级 
n   低优先级
s   包含子进程
\+   位于后台的进程组



# 数据结构与算法

[云风实现的伙伴内存分配算法](https://github.com/cloudwu/buddy)

[一篇关于跳表的不错总结](http://zhangtielei.com/posts/blog-redis-skiplist.html)以及[一个简单的跳表实现](https://github.com/begeekmyfriend/skiplist/blob/master/skiplist.h)
[Paxos小结](http://drmingdrmer.github.io/post-res/paxos-slide/pdf/paxos.html)



# Java

### 语言自身

[Java中以零拷贝的方式在不同的file descriptor之间传输数据](https://www.ibm.com/developerworks/linux/library/j-zerocopy/)

**wait/notify v.s. park/unpark**：unpark可以在park之前调，不会有那种notify在wait之前调用，导致一直在等待；指定唤醒某一个线程，而不是像notify一样随机挑一个；park/unpark模型真正解耦了线程之间的同步，线程之间不再需要一个Object或者其它变量来存储状态，不再需要关心对方的状态。[Java的LockSupport.park()实现分析](https://blog.csdn.net/hengyunabc/article/details/28126139)

### Spring

在pom.xml里同时包括了spring boot和spring cloud的包，但是不想启动spring cloud相关组件（比如当前并不需要使用consul相关功能）：

JVM参数加上`-Dspring.cloud.bootstrap.enabled=false`

想知道Spring Boot提供了哪些AutoConfiguration?[Appendix A. Common application properties](https://docs.spring.io/spring-boot/docs/2.0.3.RELEASE/reference/htmlsingle/#common-application-properties)

# Kafka

[这里列举了Kafka分区及复制一些有用的命令](https://cwiki.apache.org/confluence/display/KAFKA/Replication+tools#Replicationtools-5.AddPartitionTool)

[ZooKeeper在Kafka中的作用](https://www.quora.com/What-is-the-need-of-zookeeper-in-Apache-kafka)

### Kafka Stream

Kafka Stream能做哪些不能做哪些，这里有个很好的例子：[Why Kafka Streams didn't work for us](https://aseigneurin.github.io/2017/08/04/why-kafka-streams-didnt-work-for-us-part-1.html)。主要的原因还是Kafka Stream是根据消息的key来做aggregation的；如果要根据某个字段（比如isValid）来做，就要生成新的消息，以isValid的值（0/1）作为key，写到另一个topic里面。而Kafka Stream的并行度是根据partition来的，这里只有2个partition有值且data skew可能很严重，所以后续处理起来不够优化。我觉得Kafka Stream主要还是适合于纯粹的横向扩展型任务，有点类似于Python Celery的使用场景，不涉及到类似Spark的shuffle操作，因为它没有shuffle的能力。

[Kafka Stream examples](https://github.com/confluentinc/kafka-streams-examples)

Kafka Stream运行KTable.to方法的时候，明明提供了key和value的Serde，仍然报Serializer不匹配：

```java
ticks.map((key, value) -> new KeyValue<>(key + "-" + value.getClass().getSimpleName() + "-" + new SimpleDateFormat("[yyyy-MM-dd HH:mm]").format(value.getDate()), value))
  .groupByKey()
  .count("ticks-count")
  .to(Serdes.String(), Serdes.Long(), "ticks-count");
```

> Caused by: org.apache.kafka.streams.errors.StreamsException: A serializer (key: org.apache.kafka.common.serialization.ByteArraySerializer / value: org.apache.kafka.common.serialization.ByteArraySerializer) is not compatible to the actual key or value type (key type: java.lang.String / value type: com.github.mayaming.demo_collection.java_example.kafka.bean.MDLSHL2Snapshot). Change the default Serdes in StreamConfig or provide correct Serdes via method parameters.

原因：尽管最后的结果stream提供了正确的Serde，但是中间的map/groupByKey操作导致了一次repartition（类似于Spark的shuffle），从而需要生成一个中间topic tick-count-ticks-count-repartition，把中间数据（map那一步生成的）写入到该topic里。最后的KStream.to方法里指定的Serde对此不适用，会使用之前配的全局的Serde，因而有可能会发生无法序列化的问题。总之，在Kafka Stream里做shuffle的话要深思。

# 存储技术

[CephFS基本技术介绍(PPT)](https://www.slideshare.net/YangGuanjun/cephfs)

[Ceph介绍及原理架构分享](https://www.jianshu.com/p/cc3ece850433)

